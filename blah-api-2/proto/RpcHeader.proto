option java_package = "org.apache.hadoop.ipc.protobuf";
option java_outer_classname = "RpcHeaderProtos";
option java_generate_equals_and_hash = true;
package hadoop.common;

enum RpcKindProto {
  RPC_BUILTIN          = 0;
  RPC_WRITABLE         = 1;
  RPC_PROTOCOL_BUFFER  = 2;
}

message RpcRequestHeaderProto {
  enum OperationProto {
    RPC_FINAL_PACKET        = 0;
    RPC_CONTINUATION_PACKET = 1;
    RPC_CLOSE_CONNECTION     = 2;
  }

  optional RpcKindProto rpcKind = 1;
  optional OperationProto rpcOp = 2;
  required sint32 callId = 3;
  required bytes clientId = 4;
  optional sint32 retryCount = 5 [default = -1];
}

message RpcResponseHeaderProto {
  enum RpcStatusProto {
    SUCCESS = 0;
    ERROR = 1;
    FATAL = 2;
  }

  enum RpcErrorCodeProto {
    ERROR_APPLICATION = 1;
    ERROR_NO_SUCH_METHOD = 2;
    ERROR_NO_SUCH_PROTOCOL = 3;
    ERROR_RPC_SERVER  = 4;
    ERROR_SERIALIZING_RESPONSE = 5;
    ERROR_RPC_VERSION_MISMATCH = 6;

    FATAL_UNKNOWN = 10;
    FATAL_UNSUPPORTED_SERIALIZATION = 11;
    FATAL_INVALID_RPC_HEADER = 12;
    FATAL_DESERIALIZING_REQUEST = 13;
    FATAL_VERSION_MISMATCH = 14;
    FATAL_UNAUTHORIZED = 15;
  }

  required uint32 callId = 1;
  required RpcStatusProto status = 2;
  optional uint32 serverIpcVersionNum = 3;
  optional string exceptionClassName = 4;
  optional string errorMsg = 5;
  optional RpcErrorCodeProto errorDetail = 6;
  optional bytes clientId = 7;
  optional sint32 retryCount = 8 [default = -1];
}
